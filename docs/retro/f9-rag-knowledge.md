# F9: RAGナレッジ機能 — レトロスペクティブ

## 概要

外部Webページから収集した知識をベクトルDBに蓄積し、ユーザーの質問に関連する情報を自動検索してチャット応答に活用するRAG（Retrieval-Augmented Generation）機能を実装した。

## 実装範囲

| Issue | タイトル | 状態 |
|-------|---------|------|
| #119 | F9: RAGナレッジ機能の実装（親Issue） | 完了 |
| #114 | 仕様書作成 | 完了 |
| #115 | Embeddingプロバイダーの実装 | 完了 |
| #116 | RAGインフラの実装（チャンキング・ベクトルストア） | 完了 |
| #117 | Webクローラーの実装 | 完了 |
| #118 | RAGナレッジサービスの実装と既存コード統合 | 完了 |

関連PR: #120, #121, #151, #152, #154, #155, #156

## 主なコンポーネント

```
src/embedding/           — Embeddingプロバイダー（LM Studio/OpenAI切替）
src/rag/                 — チャンキング、ChromaDBベクトルストア
src/services/web_crawler.py    — SSRF対策付きWebクローラー
src/services/rag_knowledge.py  — オーケストレーションサービス
```

**Slackコマンド:**

- `@bot rag crawl <URL> [パターン]` — リンク集から一括取り込み
- `@bot rag add <URL>` — 単一ページ取り込み
- `@bot rag status` — 統計表示
- `@bot rag delete <URL>` — 削除

## うまくいったこと

### 1. 仕様駆動開発の徹底

- 先に詳細な仕様書（f9-rag-knowledge.md）を作成してから実装に入った
- 35個の受け入れ条件（AC）を定義し、テスト名と対応づけ
- 実装中に仕様変更が必要になった場合も、先に仕様書を更新してから実装

### 2. 既存パターンの再利用

| パターン | 参照元 | 適用先 |
|---------|--------|--------|
| 抽象基底クラス | `LLMProvider` | `EmbeddingProvider` |
| ファクトリ関数 | `get_provider_for_service()` | `get_embedding_provider()` |
| 同期APIラップ | `feed_collector.py` | ChromaDB操作 |
| オプショナル注入 | `ThreadHistoryService` | `RAGKnowledgeService` |
| コマンドルーティング | `feed` コマンド | `rag` コマンド |

### 3. セキュリティ対策の事前設計

SSRF対策を仕様書段階で明確化：

- ドメインホワイトリスト（必須）
- スキーム制限（http/httpsのみ）
- リダイレクト追従無効化
- クロール遅延・ページ数制限

### 4. テスト設計

- `chromadb.EphemeralClient()` でファイルシステム副作用なしにテスト
- AC番号ベースのテスト命名でトレーサビリティ確保
- Slackコマンドの統合テストは `pytest.skip()` で明示的にスキップ

## 改善点・ハマったこと

### 1. ChromaDBテレメトリのエラー

**問題**: ChromaDBがデフォルトでテレメトリを送信しようとし、失敗時にエラーログが出力された。

**対応**:

- `ChromaSettings(anonymized_telemetry=False)` でテレメトリ無効化
- ロガーレベルをCRITICALに設定してエラー抑制

**教訓**: 外部ライブラリのデフォルト動作（テレメトリ、ログ出力等）を事前に確認する

### 2. Pythonバージョン変更の波及

**問題**: sentence-transformers（onnxruntime）がPython 3.11以上を要求。テスト実行時にエラー発生。

**対応**: `.python-version`, `pyproject.toml`, `README.md` など複数ファイルを更新。

**教訓**:

- 依存パッケージ追加時はPythonバージョン要件を事前確認
- ML系ライブラリは特にバージョン制約が厳しい

### 3. アンカー違いの重複取り込み

**問題**: `rag crawl` で同一ページのアンカー違い（`#m`, `#movie`等）が別ページとして取り込まれた。

**対応**: Issue #161 として課題化。URLからフラグメントを除去する改善を予定。

**教訓**: クローラーのURL正規化は早期に実装すべき

### 4. Settings()の毎回インスタンス化

**問題**: `ChatService.respond()` 内で毎回 `Settings()` をインスタンス化していた。

**対応**: `get_settings()` （キャッシュ済み）を使用するよう修正。

**教訓**: 設定値の取得は初期化時またはキャッシュ経由で行う

### 5. crawl中のフィードバック不足

**問題**: クロール処理中、完了までSlackで反応がなく状況がわからない。

**対応**: Issue #158 として課題化。進捗表示の改善を予定。

**教訓**: 長時間処理には進捗フィードバックが必要

## 今後の課題（Issue化済み）

| Issue | 内容 |
|-------|------|
| #157 | ドメイン許可リストをSlackから動的管理 |
| #158 | crawl進捗フィードバック追加 |
| #159 | URL安全性チェック（Google Safe Browsing API） |
| #160 | robots.txt の解析・遵守 |
| #161 | アンカー違いの重複取り込み防止 |

## 次に活かすこと

1. **外部ライブラリのデフォルト動作を確認する** — テレメトリ、ログレベル、ネットワーク接続等

2. **URL正規化は早期に実装する** — フラグメント除去、末尾スラッシュ統一など

3. **長時間処理には進捗フィードバックを設計に含める** — クローラー、バッチ処理など

4. **設定値の取得はキャッシュ経由で** — `get_settings()` パターンを使用

5. **仕様書のコード例は実装と整合させる** — 型の違い（`list[str]` vs `str`）など細部も確認

---

## 追記: Issue #169 エンコーディング問題の修正

### 概要

RAG検索結果がチャット回答に反映されない問題（#169）を調査・修正した。

**根本原因**: Shift_JISエンコーディングのWebページ（way78.com等）がUTF-8として誤デコードされ、日本語テキストが文字化け状態でChromaDBに保存されていた。

### 修正内容（PR #172）

| ファイル | 変更内容 |
|---------|---------|
| `src/services/web_crawler.py` | `charset-normalizer`によるエンコーディング自動検出を追加 |
| `pyproject.toml` | `charset-normalizer>=3.0,<4` 依存関係追加 |
| `tests/test_web_crawler.py` | Shift_JIS/UTF-8/EUC-JP/フォールバックのテスト5件追加 |

### エージェントチーム開発の効果

今回、Claude Codeのエージェントチーム機能を初めて活用して修正を実施した。

**チーム構成**:

| 役割 | 担当タスク |
|------|-----------|
| リーダー | 統括・方針決定・PR作成 |
| 実装担当 | `web_crawler.py`のエンコーディング検出実装 |
| テスト担当 | テストコード作成（5件） |
| 依存関係担当 | `pyproject.toml`への依存追加 |

**結果**: Copilotレビューで**指摘ゼロ**（従来のPRでは毎回指摘があった）

### チーム開発による品質向上の要因

1. **役割分離による専門性**
   - 各エージェントが専門タスクに集中
   - 実装者とテスト作成者が別なので、第三者視点でテストが書かれた

2. **タスク依存関係の制御**
   - テストタスクが実装タスクにブロックされる設定
   - 実装完了後にテスト作成という流れが保証された

3. **最終品質ゲート**
   - test-runnerで全チェック（pytest/mypy/ruff/markdownlint）を通してからコミット
   - 複数の視点が入ることで、単独作業では見落としがちなポイントが事前にカバーされた

4. **設計の事前共有**
   - リーダーが修正方針（`_decode_response`ヘルパー追加など）を明示
   - 実装のブレがなく、一貫性のあるコードに

### 教訓

- **エンコーディングは明示的に検出する**: `aiohttp`の`resp.text()`はHTTPヘッダーのみを参照し、HTMLの`<meta charset>`を無視する。`charset-normalizer`等で明示的に検出すべき。

- **チーム開発は品質向上に有効**: 役割分離・タスク依存関係・複数視点により、単独作業より高品質なコードが生まれやすい。

- **クロールデータは再取得が必要**: 文字化け状態で保存されたデータは修正後に再クロールが必要。

### 関連Issue

| Issue | 内容 |
|-------|------|
| #169 | RAG検索結果がチャット回答に反映されない（本件） |
| #173 | RAG検索精度の評価・検証の仕組みを導入 |

## 参考

- 仕様書: [docs/specs/f9-rag-knowledge.md](../specs/f9-rag-knowledge.md)
- 関連レトロ: [f9-rag-infrastructure.md](./f9-rag-infrastructure.md)（チャンキング・ベクトルストア詳細）
- エージェントチーム仕様: [docs/specs/agent-teams.md](../specs/agent-teams.md)
