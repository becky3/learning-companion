# F9: RAGナレッジ機能 — レトロスペクティブ

## 概要

外部Webページから収集した知識をベクトルDBに蓄積し、ユーザーの質問に関連する情報を自動検索してチャット応答に活用するRAG（Retrieval-Augmented Generation）機能を実装した。

## 実装範囲

| Issue | タイトル | 状態 |
|-------|---------|------|
| #119 | F9: RAGナレッジ機能の実装（親Issue） | 完了 |
| #114 | 仕様書作成 | 完了 |
| #115 | Embeddingプロバイダーの実装 | 完了 |
| #116 | RAGインフラの実装（チャンキング・ベクトルストア） | 完了 |
| #117 | Webクローラーの実装 | 完了 |
| #118 | RAGナレッジサービスの実装と既存コード統合 | 完了 |
| #161 | アンカー違いの重複取り込み防止 | 完了 |
| #176 | RAG評価・可視化 Phase 2（類似度閾値フィルタリング） | 完了 |
| #158 | crawl進捗フィードバック追加 | 完了 |

関連PR: #120, #121, #151, #152, #154, #155, #156, #187, #192, #237

## 主なコンポーネント

```
src/embedding/           — Embeddingプロバイダー（LM Studio/OpenAI切替）
src/rag/                 — チャンキング、ChromaDBベクトルストア
src/services/web_crawler.py    — SSRF対策付きWebクローラー
src/services/rag_knowledge.py  — オーケストレーションサービス
```

**Slackコマンド:**

- `@bot rag crawl <URL> [パターン]` — リンク集から一括取り込み
- `@bot rag add <URL>` — 単一ページ取り込み
- `@bot rag status` — 統計表示
- `@bot rag delete <URL>` — 削除

## うまくいったこと

### 1. 仕様駆動開発の徹底

- 先に詳細な仕様書（f9-rag-knowledge.md）を作成してから実装に入った
- 35個の受け入れ条件（AC）を定義し、テスト名と対応づけ
- 実装中に仕様変更が必要になった場合も、先に仕様書を更新してから実装

### 2. 既存パターンの再利用

| パターン | 参照元 | 適用先 |
|---------|--------|--------|
| 抽象基底クラス | `LLMProvider` | `EmbeddingProvider` |
| ファクトリ関数 | `get_provider_for_service()` | `get_embedding_provider()` |
| 同期APIラップ | `feed_collector.py` | ChromaDB操作 |
| オプショナル注入 | `ThreadHistoryService` | `RAGKnowledgeService` |
| コマンドルーティング | `feed` コマンド | `rag` コマンド |

### 3. セキュリティ対策の事前設計

SSRF対策を仕様書段階で明確化：

- ドメインホワイトリスト（必須）
- スキーム制限（http/httpsのみ）
- リダイレクト追従無効化
- クロール遅延・ページ数制限

### 4. テスト設計

- `chromadb.EphemeralClient()` でファイルシステム副作用なしにテスト
- AC番号ベースのテスト命名でトレーサビリティ確保
- Slackコマンドの統合テストは `pytest.skip()` で明示的にスキップ

## 改善点・ハマったこと

### 1. ChromaDBテレメトリのエラー

**問題**: ChromaDBがデフォルトでテレメトリを送信しようとし、失敗時にエラーログが出力された。

**対応**:

- `ChromaSettings(anonymized_telemetry=False)` でテレメトリ無効化
- ロガーレベルをCRITICALに設定してエラー抑制

**教訓**: 外部ライブラリのデフォルト動作（テレメトリ、ログ出力等）を事前に確認する

### 2. Pythonバージョン変更の波及

**問題**: sentence-transformers（onnxruntime）がPython 3.11以上を要求。テスト実行時にエラー発生。

**対応**: `.python-version`, `pyproject.toml`, `README.md` など複数ファイルを更新。

**教訓**:

- 依存パッケージ追加時はPythonバージョン要件を事前確認
- ML系ライブラリは特にバージョン制約が厳しい

### 3. アンカー違いの重複取り込み

**問題**: `rag crawl` で同一ページのアンカー違い（`#m`, `#movie`等）が別ページとして取り込まれた。

**対応**: PR #187 で解決。`validate_url()` に `urldefrag()` によるフラグメント除去を追加し、`crawl_index_page()` での重複排除、`_ingest_crawled_page()` と `delete_source()` での防御的正規化を実装。

**実装のポイント**:

- 正規化を `validate_url()` に集約することで、下流の全処理で一貫したURLが使用される設計
- `rag_knowledge.py` 側にも防御的に `urldefrag()` を適用（外部入力の安全性確保）
- AC36/AC37として受け入れ条件を追加し、8件のテストでカバー

**教訓**: クローラーのURL正規化は早期に実装すべき。今回の修正は小規模だったが、正規化が遅れるとDB内に重複データが蓄積され、後からのクリーンアップが困難になる

### 4. Settings()の毎回インスタンス化

**問題**: `ChatService.respond()` 内で毎回 `Settings()` をインスタンス化していた。

**対応**: `get_settings()` （キャッシュ済み）を使用するよう修正。

**教訓**: 設定値の取得は初期化時またはキャッシュ経由で行う

### 5. crawl中のフィードバック不足（解決済み: PR #237）

**問題**: クロール処理中、完了までSlackで反応がなく状況がわからない。

**対応**: PR #237 で案2（リアルタイム進捗・スレッド内投稿）を実装。

**実装のポイント**:

- `progress_callback` パターンでサービス層とハンドラ層を疎結合
- スレッド内投稿でチャンネルへの通知過多を防止
- 開始メッセージで即座にフィードバック → ユーザーの不安を解消
- `RAG_CRAWL_PROGRESS_INTERVAL` で進捗報告間隔を設定可能

**出力例**:

```
bot: クロールを開始しました... (リンク収集中)
  └─ 5ページ取得中...
  └─ 10ページ取得中...
  └─ 完了: 15ページ / 128チャンク / エラー: 2件
```

**教訓**: 長時間処理には進捗フィードバックが必要。コールバックパターンで層を分離すると、テストも書きやすい

### 6. Phase 2: 根本原因分析の不足（Issue #176）

**問題**: Slackボットで「りゅうおう」検索が動かない事象に対し、根本原因を十分に分析せずに「Embeddingモデルの日本語対応が弱い」と早合点し、モデル変更を提案した。

**経緯**:

1. 「りゅうおう」（ひらがな）で検索 → distance 0.70（閾値0.5超え）
2. 「竜王」（漢字）で検索 → distance 0.46（閾値内）
3. → 「ひらがなの処理が弱いEmbeddingモデルの問題」と判断
4. → BGE-M3等の多言語モデルへの変更を提案
5. → チームを組んでモデル調査を実施

**実際の原因**:

チャンクの中身を調べると、「りゅうおう」を含むチャンクは：

- 342〜500文字の長さ
- 内容は数値テーブルデータが大半（`90 75 100 15 15 15 0 0 0` など）
- 「りゅうおう」はチャンクのごく一部

**純粋なベクトル検索の特性**として、短いクエリ「りゅうおう」と、数値だらけの長いチャンクのベクトルは距離が遠くなる。これは**チャンキング戦略とコンテンツ構造の問題**であり、Embeddingモデルの問題ではなかった。

**対応**: Issue #194（Embeddingモデル変更）をクローズし、Issue #195（チャンキング改善・ハイブリッド検索）として正しい課題を起票。

**教訓**:

- **表面的な現象から解決策に飛びつかない** — 「ひらがなで動かない→モデルが悪い」は短絡的だった
- **データの中身を先に確認する** — チャンクの内容を最初に見ていれば、数値テーブルが原因とすぐにわかった
- **ベクトル検索の特性を理解する** — 同じテキストを含んでいても、周囲のコンテキストでベクトルは大きく変わる
- **仮説を立てたら検証してから行動する** — モデル変更の提案前に、本当にモデルの問題かを検証すべきだった

## 今後の課題（Issue化済み）

| Issue | 内容 | 状態 |
|-------|------|------|
| #157 | ドメイン許可リストをSlackから動的管理 | 未着手 |
| ~~#158~~ | ~~crawl進捗フィードバック追加~~ | PR #237 で対応済み |
| #159 | URL安全性チェック（Google Safe Browsing API） | 未着手 |
| #160 | robots.txt の解析・遵守 | 未着手 |
| ~~#161~~ | ~~アンカー違いの重複取り込み防止~~ | PR #187 で対応済み |
| ~~#194~~ | ~~Embeddingモデル変更~~ | クローズ（誤診断） |
| #195 | チャンキング改善・ハイブリッド検索 | 未着手 |

## 次に活かすこと

1. **外部ライブラリのデフォルト動作を確認する** — テレメトリ、ログレベル、ネットワーク接続等

2. **URL正規化は早期に実装する** — フラグメント除去、末尾スラッシュ統一など

3. **長時間処理には進捗フィードバックを設計に含める** — クローラー、バッチ処理など

4. **設定値の取得はキャッシュ経由で** — `get_settings()` パターンを使用

5. **仕様書のコード例は実装と整合させる** — 型の違い（`list[str]` vs `str`）など細部も確認

6. **問題の根本原因を特定してから解決策を提案する** — 表面的な現象（「ひらがなで動かない」）から解決策（「モデル変更」）に飛びつかない。まずデータの中身を確認し、仮説を検証する

7. **ベクトル検索の特性を理解する** — 同じキーワードを含んでいても、チャンク全体のコンテキストでベクトルは大きく変わる。キーワード完全一致が必要ならハイブリッド検索を検討

## 参考

- 仕様書: [docs/specs/f9-rag-knowledge.md](../specs/f9-rag-knowledge.md)
- 関連レトロ: [f9-rag-infrastructure.md](./f9-rag-infrastructure.md)（チャンキング・ベクトルストア詳細）
