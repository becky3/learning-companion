# F2: 情報収集・配信

## 概要

RSSフィードや特定サイトから学習関連の記事を自動収集し、ローカルLLMで要約したうえで、毎朝Slackの専用チャンネルに自動配信する。また、オンラインLLMを使って新しい情報源の探索・提案も行う。

## ユーザーストーリー

- ユーザーとして、毎朝Slackの専用チャンネルで、自分の学習テーマに関する最新記事の要約を受け取りたい。
- 管理者として、RSSフィードの追加・削除・カテゴリ分けをしたい。
- ユーザーとして、ボットに「この分野の情報源を追加して」と頼み、新しいRSSフィードを提案・追加してもらいたい。

## 入出力仕様

### RSS収集

**入力:**
- DBに登録されたRSSフィードURL一覧（feedsテーブル、enabled=true）

**処理:**
1. 各フィードからfeedparserで記事を取得
2. 既にarticlesテーブルに存在するURLはスキップ（重複排除）
3. 新規記事ごとにローカルLLMで要約を生成
4. articlesテーブルに保存

**出力:**
- articlesテーブルに新規記事レコード（title, url, summary, published_at, collected_at）

### 毎朝配信

**入力:**
- 前日〜当日に収集された記事（articlesテーブル）

**処理:**
1. カテゴリごとに記事をグループ化
2. Slack用にフォーマット

**出力（Slackメッセージ例）:**
```
:newspaper: 今日の学習ニュース (2026-02-01)

【Python】
• *asyncioの新機能がPython 3.13で追加* - asyncioにTaskGroupが正式導入され...
  :link: https://example.com/article1

【機械学習】
• *transformerの効率化手法まとめ* - 最新の軽量化手法としてQuantization...
  :link: https://example.com/article2

:bulb: 気になる記事があれば、スレッドで聞いてね！
```

### 情報源探索

**入力:**
- ユーザーからの「この分野の情報源を追加して」等のリクエスト

**処理:**
1. オンラインLLMに分野名を渡し、おすすめのRSSフィード/サイトを提案させる
2. ユーザーに提案を提示
3. 承認されたらfeedsテーブルに追加

## 受け入れ条件

- [ ] AC1: feedsテーブルに登録されたRSSフィードから記事を取得できる
- [ ] AC2: 既に収集済みの記事はスキップする（URL重複チェック）
- [ ] AC3: 新規記事をローカルLLMで要約し、articlesテーブルに保存する
- [ ] AC4: 毎朝指定時刻にスケジューラが収集・配信ジョブを実行する
- [ ] AC5: 専用チャンネルにカテゴリ別でフォーマットされた記事要約を投稿する
- [ ] AC6: ユーザーのリクエストに応じてオンラインLLMで新しい情報源を提案できる
- [ ] AC7: フィードの追加・削除・有効/無効切替ができる
- [ ] AC8: RSS取得失敗時はエラーをログに記録し、他のフィードの処理を継続する

## 使用LLMプロバイダー

| 処理 | プロバイダー |
|------|-------------|
| 記事要約 | ローカル (LM Studio) |
| 情報源探索・提案 | オンライン (OpenAI/Claude) |

## 関連ファイル

| ファイル | 役割 |
|---------|------|
| `src/services/feed_collector.py` | RSS取得・新規記事判定 |
| `src/services/summarizer.py` | ローカルLLMによる記事要約 |
| `src/scheduler/jobs.py` | 毎朝の定期実行ジョブ |
| `src/slack/handlers.py` | 情報源追加リクエストのハンドリング |
| `src/db/models.py` | feeds, articlesモデル |

## テスト方針

- feedparserのレスポンスをモックしてfeed_collectorをテスト
- LLMをモックして要約生成をテスト
- 重複排除ロジックのユニットテスト
- スケジューラの起動・ジョブ登録をテスト
- Slackメッセージフォーマットのスナップショットテスト
