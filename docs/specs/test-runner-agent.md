# テストランナーサブエージェント

## 概要

pytest によるテスト実行を自動化するClaude Codeサブエージェント。テストの実行、失敗時の分析、修正提案、再実行までを一貫して行い、開発者がテストに関する手動作業を最小化する。

## 背景

Learning Companionプロジェクトは仕様駆動開発を採用しており、各機能の受け入れ条件（AC）に対応するテストが `tests/` ディレクトリに配置されている。テスト実行は開発フローの重要な部分だが、以下の課題がある:

- テスト実行コマンドの記憶・入力が煩雑
- テスト失敗時のエラー分析に時間がかかる
- 修正後の再実行を忘れがち
- カバレッジ確認やレポート生成が手作業

これらを解消するため、テスト実行から分析・修正提案・再実行までを自動化するサブエージェントを実装する。

## ユーザーストーリー

- 開発者として、実装完了後に `test-runnerサブエージェント` でテストを実行し、品質を確認したい
- 開発者として、テスト失敗時に自動でエラー分析と修正提案を受けたい
- 開発者として、特定のテストファイルやテストケースのみを実行したい
- 開発者として、カバレッジレポートを自動生成してテストの網羅性を把握したい

## 技術仕様

### サブエージェント定義

**ファイル**: `.claude/agents/test-runner.md`

**メタデータ:**
```yaml
name: test-runner
description: pytest による自動テスト実行・分析・修正提案を行う専門家。テスト失敗の原因特定と解決策提示、再実行までを一貫してサポート。
tools: Bash, Read, Grep, Glob, Edit
model: sonnet
permissionMode: default
```

### テスト実行パターン

以下の実行パターンをサポートする。具体的なコマンド例はサブエージェント定義（`.claude/agents/test-runner.md`）を参照。

| パターン | 説明 |
|---------|------|
| 全テスト実行 | すべてのテストケースを実行 |
| 特定ファイル実行 | 指定されたテストファイルのみ実行 |
| 特定テストケース実行 | 関数名やパターンでテストを絞り込み実行 |
| 詳細出力モード | 失敗時の詳細情報を表示 |
| カバレッジ測定 | pytest-cov によるカバレッジレポート生成（dev 依存に `pytest-cov>=5.0,<6` が必要） |

### 処理フロー

1. **テスト対象の特定**
   - 引数でファイルパスやテスト名が指定されていればそれを実行
   - 未指定なら全テストを実行

2. **テスト実行**
   - `uv run pytest` でテストを実行
   - 出力を解析してテスト結果を取得

3. **結果の分析**
   - **成功時**: 実行件数、実行時間を報告
   - **失敗時**: 失敗したテストケース、エラーメッセージ、スタックトレースを抽出

4. **失敗時の詳細調査**
   - 失敗したテストファイルとテスト対象コードを読み込み
   - エラーの原因を特定（ロジックバグ、型エラー、アサーション失敗など）
   - 修正案を提示

5. **修正適用（オプション）**
   - ユーザーが承認した場合、修正を適用
   - 修正後に再度テストを実行して確認

6. **レポート生成**
   - テスト結果のサマリー
   - 失敗した場合は原因と修正案
   - カバレッジ情報（要求された場合）

### 入出力仕様

#### 入力

ユーザーがClaude Codeで以下のように呼び出す:

```
test-runnerサブエージェントで全テストを実行してください
```

または:

```
test-runnerサブエージェントで tests/test_feed_collector.py を実行してください
```

または:

```
test-runnerサブエージェントでカバレッジを測定してください
```

#### 出力

**成功時:**
```markdown
### テスト実行結果 ✅

- **実行件数**: 35 passed
- **実行時間**: 2.45s
- **カバレッジ**: 92% (要求された場合)

すべてのテストが成功しました。
```

**失敗時:**
```markdown
### テスト実行結果 ❌

- **成功**: {N} passed
- **失敗**: {M} failed
- **実行時間**: {X.XX}s

#### 失敗したテスト

**{番号}. {テストファイル}::{テストケース名}**

**エラー内容:** エラーメッセージの引用
**原因:** エラーの根本原因の分析
**修正案:** ファイルパス・行番号付きの具体的な修正コード

#### 次のステップ

修正を適用するかユーザーに確認
```

> **注**: 失敗時レポートの詳細なフォーマットとサンプルはサブエージェント定義（`.claude/agents/test-runner.md`）を参照。

## 使用LLMプロバイダー

**Claude Code (Sonnet モデル)** — サブエージェントとして使用

**選定理由:**
- テスト実行、エラー分析、修正提案は、コードの文脈理解と論理的推論が必要
- サブエージェント定義のメタデータで `model: sonnet` を指定し、Sonnetモデルで実行
- pytestの出力解析、スタックトレースの読解、コード修正案の生成には高度な推論力が重要

## 受け入れ条件

- [ ] AC1: `.claude/agents/test-runner.md` が正しく作成され、Claude Codeから呼び出せる
- [ ] AC2: 引数なしで全テストを実行できる
- [ ] AC3: ファイル指定で特定のテストファイルのみ実行できる
- [ ] AC4: テストケース名指定で特定のテストのみ実行できる
- [ ] AC5: テスト成功時に実行件数と実行時間を報告する
- [ ] AC6: テスト失敗時に失敗したテストケースとエラー内容を抽出できる
- [ ] AC7: 失敗したテストの原因を分析し、具体的な修正案を提示できる
- [ ] AC8: カバレッジ測定を実行し、カバレッジ率を報告できる
- [ ] AC9: 修正提案後、ユーザー承認を経て修正を適用し再実行できる
- [ ] AC10: uv環境でのpytest実行に対応している

## 関連ファイル

| ファイル | 役割 |
|---------|------|
| `.claude/agents/test-runner.md` | サブエージェント定義（テスト実行・分析プロンプト） |
| `tests/*.py` | 実行対象のテストファイル |
| `pyproject.toml` | pytest設定（asyncio_mode等） |
| `CLAUDE.md` | テスト実行コマンド、コーディング規約 |

## テスト方針

Claude Codeサブエージェントは実行時テストが中心となるため、以下を手動で確認:

### 基本動作テスト

- [ ] 全テスト実行が正しく動作するか
- [ ] 特定ファイルのテスト実行が正しく動作するか
- [ ] テスト失敗時にエラー分析が適切に行われるか
- [ ] 修正案が実用的で正確か

### エラーハンドリング

- [ ] 存在しないテストファイルを指定した場合のエラーメッセージ
- [ ] uv環境が未セットアップの場合のエラーメッセージ

### レポート品質

- [ ] 成功・失敗の判定が正確か
- [ ] スタックトレースから原因を正しく特定できるか
- [ ] 修正案が具体的でファイルパス・行番号を含むか

## 拡張性

将来的に以下の機能を追加可能:

- **自動修正モード**: 失敗したテストを自動で修正（`permissionMode: acceptEdits` のバリアント）
- **CI/CD統合**: PR作成時に自動でテストを実行し、結果をコメント
- **パフォーマンス測定**: テスト実行時間の推移をトラッキング
- **並列実行**: `pytest -n auto` による高速化
- **カスタムレポート**: HTML/JSONフォーマットでのレポート出力
