# テストランナーサブエージェント

## 概要

pytest によるテスト実行を自動化するClaude Codeサブエージェント。テストの実行、失敗時の分析、修正提案、再実行までを一貫して行い、開発者がテストに関する手動作業を最小化する。

## 背景

Learning Companionプロジェクトは仕様駆動開発を採用しており、各機能の受け入れ条件（AC）に対応するテストが `tests/` ディレクトリに配置されている。テスト実行は開発フローの重要な部分だが、以下の課題がある:

- テスト実行コマンドの記憶・入力が煩雑
- テスト失敗時のエラー分析に時間がかかる
- 修正後の再実行を忘れがち
- カバレッジ確認やレポート生成が手作業

これらを解消するため、テスト実行から分析・修正提案・再実行までを自動化するサブエージェントを実装する。

## ユーザーストーリー

- 開発者として、実装完了後に `test-runnerサブエージェント` でテストを実行し、品質を確認したい
- 開発者として、テスト失敗時に自動でエラー分析と修正提案を受けたい
- 開発者として、特定のテストファイルやテストケースのみを実行したい
- 開発者として、カバレッジレポートを自動生成してテストの網羅性を把握したい

## 技術仕様

### サブエージェント定義

**ファイル**: `.claude/agents/test-runner.md`

**メタデータ:**
```yaml
name: test-runner
description: pytest による自動テスト実行・分析・修正提案を行う専門家。テスト失敗の原因特定と解決策提示、再実行までを一貫してサポート。
tools: Bash, Read, Grep, Glob, Edit
model: sonnet
permissionMode: default
```

### テスト実行パターン

#### 1. 全テスト実行

すべてのテストケースを実行:
```bash
uv run pytest
```

#### 2. 特定ファイルのテスト実行

指定されたテストファイルのみ実行:
```bash
uv run pytest tests/test_feed_collector.py
```

#### 3. 特定テストケースの実行

関数名やパターンでテストを絞り込み:
```bash
uv run pytest tests/test_feed_collector.py::test_ac1_rss_feed_is_fetched_and_parsed
uv run pytest -k "ac1"
```

#### 4. 詳細出力モード

失敗時の詳細情報を表示:
```bash
uv run pytest -v
uv run pytest -vv  # さらに詳細
```

#### 5. カバレッジ測定

pytest-cov によるカバレッジレポート生成:
```bash
uv run pytest --cov=src --cov-report=term-missing
```

> **前提**: `pyproject.toml` の dev 依存に `pytest-cov>=5.0,<6` が含まれていること。

### 処理フロー

1. **テスト対象の特定**
   - 引数でファイルパスやテスト名が指定されていればそれを実行
   - 未指定なら全テストを実行

2. **テスト実行**
   - `uv run pytest` でテストを実行
   - 出力を解析してテスト結果を取得

3. **結果の分析**
   - **成功時**: 実行件数、実行時間を報告
   - **失敗時**: 失敗したテストケース、エラーメッセージ、スタックトレースを抽出

4. **失敗時の詳細調査**
   - 失敗したテストファイルとテスト対象コードを読み込み
   - エラーの原因を特定（ロジックバグ、型エラー、アサーション失敗など）
   - 修正案を提示

5. **修正適用（オプション）**
   - ユーザーが承認した場合、修正を適用
   - 修正後に再度テストを実行して確認

6. **レポート生成**
   - テスト結果のサマリー
   - 失敗した場合は原因と修正案
   - カバレッジ情報（要求された場合）

### 入出力仕様

#### 入力

ユーザーがClaude Codeで以下のように呼び出す:

```
test-runnerサブエージェントで全テストを実行してください
```

または:

```
test-runnerサブエージェントで tests/test_feed_collector.py を実行してください
```

または:

```
test-runnerサブエージェントでカバレッジを測定してください
```

#### 出力

**成功時:**
```markdown
### テスト実行結果 ✅

- **実行件数**: 35 passed
- **実行時間**: 2.45s
- **カバレッジ**: 92% (要求された場合)

すべてのテストが成功しました。
```

**失敗時:**
```markdown
### テスト実行結果 ❌

- **成功**: 33 passed
- **失敗**: 2 failed
- **実行時間**: 2.67s

#### 失敗したテスト

**1. tests/test_feed_collector.py::test_ac3_articles_are_summarized_by_local_llm**

**エラー内容:**
```
AssertionError: assert 'mock summary' == '要約テスト'
```

**原因:**
- テストでは `summarizer.summarize()` が "要約テスト" を返すことを期待しているが、実際には "mock summary" が返されている
- モックの戻り値設定が誤っている可能性

**修正案:**
```python
# tests/test_feed_collector.py:47
summarizer.summarize.return_value = "要約テスト"  # 期待値に合わせる
```

**2. tests/test_chat_service.py::test_ac2_conversation_history_maintained**

**エラー内容:**
```
TypeError: ChatService.__init__() missing 1 required positional argument: 'session_factory'
```

**原因:**
- ChatService の初期化に `session_factory` 引数が必要だが、テストで渡していない
- ChatService の仕様変更に対応していない

**修正案:**
```python
# tests/test_chat_service.py:31
service = ChatService(
    llm=mock_provider,
    session_factory=db_factory  # 追加
)
```

#### 次のステップ

上記の修正を適用しますか？修正後に再度テストを実行します。
```

## 使用LLMプロバイダー

**Claude Code (Sonnet モデル)** — サブエージェントとして使用

**選定理由:**
- テスト実行、エラー分析、修正提案は、コードの文脈理解と論理的推論が必要
- サブエージェント定義のメタデータで `model: sonnet` を指定し、Sonnetモデルで実行
- pytestの出力解析、スタックトレースの読解、コード修正案の生成には高度な推論力が重要

## 受け入れ条件

- [ ] AC1: `.claude/agents/test-runner.md` が正しく作成され、Claude Codeから呼び出せる
- [ ] AC2: 引数なしで全テストを実行できる
- [ ] AC3: ファイル指定で特定のテストファイルのみ実行できる
- [ ] AC4: テストケース名指定で特定のテストのみ実行できる
- [ ] AC5: テスト成功時に実行件数と実行時間を報告する
- [ ] AC6: テスト失敗時に失敗したテストケースとエラー内容を抽出できる
- [ ] AC7: 失敗したテストの原因を分析し、具体的な修正案を提示できる
- [ ] AC8: カバレッジ測定を実行し、カバレッジ率を報告できる
- [ ] AC9: 修正提案後、ユーザー承認を経て修正を適用し再実行できる
- [ ] AC10: uv環境でのpytest実行に対応している

## 関連ファイル

| ファイル | 役割 |
|---------|------|
| `.claude/agents/test-runner.md` | サブエージェント定義（テスト実行・分析プロンプト） |
| `tests/*.py` | 実行対象のテストファイル |
| `pyproject.toml` | pytest設定（asyncio_mode等） |
| `CLAUDE.md` | テスト実行コマンド、コーディング規約 |

## テスト方針

Claude Codeサブエージェントは実行時テストが中心となるため、以下を手動で確認:

### 基本動作テスト

- [ ] 全テスト実行が正しく動作するか
- [ ] 特定ファイルのテスト実行が正しく動作するか
- [ ] テスト失敗時にエラー分析が適切に行われるか
- [ ] 修正案が実用的で正確か

### エラーハンドリング

- [ ] 存在しないテストファイルを指定した場合のエラーメッセージ
- [ ] uv環境が未セットアップの場合のエラーメッセージ

### レポート品質

- [ ] 成功・失敗の判定が正確か
- [ ] スタックトレースから原因を正しく特定できるか
- [ ] 修正案が具体的でファイルパス・行番号を含むか

## 拡張性

将来的に以下の機能を追加可能:

- **自動修正モード**: 失敗したテストを自動で修正（`permissionMode: acceptEdits` のバリアント）
- **CI/CD統合**: PR作成時に自動でテストを実行し、結果をコメント
- **パフォーマンス測定**: テスト実行時間の推移をトラッキング
- **並列実行**: `pytest -n auto` による高速化
- **カスタムレポート**: HTML/JSONフォーマットでのレポート出力
