"""ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ«ãƒ¼ã‚¿ãƒ¼ â€” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° + ã‚µãƒ¼ãƒ“ã‚¹å±¤å‘¼ã³å‡ºã—.

ä»•æ§˜: docs/specs/features/cli-adapter.md
handlers.py ã® _process_message ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç§»æ¤ã—ãŸã‚¯ãƒ©ã‚¹ã€‚
"""

from __future__ import annotations

import asyncio
import csv
import io
import logging
import re
import socket
from datetime import datetime
from typing import TYPE_CHECKING, Literal
from urllib.parse import urlparse
from zoneinfo import ZoneInfo

import httpx

from src.mcp_bridge.client_manager import MCPToolNotFoundError
from src.messaging.port import IncomingMessage, MessagingPort
from src.services.chat import ChatService
from src.services.topic_recommender import TopicRecommender
from src.services.user_profiler import UserProfiler

if TYPE_CHECKING:
    from slack_sdk.web.async_client import AsyncWebClient
    from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker

    from src.mcp_bridge.client_manager import MCPClientManager
    from src.services.feed_collector import FeedCollector

logger = logging.getLogger(__name__)

_PROFILE_KEYWORDS = ("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "profile")
_TOPIC_KEYWORDS = ("ãŠã™ã™ã‚", "ãƒˆãƒ”ãƒƒã‚¯", "ä½•ã‚’å­¦ã¶", "ä½•å­¦ã¶", "å­¦ç¿’ææ¡ˆ", "recommend")
_DELIVER_KEYWORDS = ("deliver",)
_FEED_KEYWORDS = ("feed",)
_RAG_KEYWORDS = ("rag",)
_STATUS_KEYWORDS = ("status", "info")


def _parse_feed_command(text: str) -> tuple[str, list[str], str]:
    """feedã‚³ãƒãƒ³ãƒ‰ã‚’è§£æã™ã‚‹."""
    tokens = text.split()
    if len(tokens) < 2:
        return ("", [], "")

    subcommand = tokens[1].lower()
    urls: list[str] = []
    category_tokens: list[str] = []

    for token in tokens[2:]:
        cleaned = token.strip("<>")
        if "|" in cleaned:
            cleaned = cleaned.split("|")[0]

        if cleaned.startswith("http://") or cleaned.startswith("https://"):
            parsed_url = urlparse(cleaned)
            if parsed_url.netloc:
                urls.append(cleaned)
        elif cleaned.startswith("--"):
            pass
        else:
            category_tokens.append(token)

    category = " ".join(category_tokens) if category_tokens else "ä¸€èˆ¬"
    return (subcommand, urls, category)


def _format_uptime(seconds: float) -> str:
    """ç¨¼åƒæ™‚é–“ã‚’ã€ŒNæ™‚é–“Måˆ†ã€å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹."""
    total_minutes = int(seconds) // 60
    hours = total_minutes // 60
    minutes = total_minutes % 60
    if hours > 0:
        return f"{hours}æ™‚é–“{minutes}åˆ†"
    return f"{minutes}åˆ†"


def _build_status_message(
    timezone: str, env_name: str, bot_start_time: datetime | None = None
) -> str:
    """ãƒœãƒƒãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ã™ã‚‹ (F7)."""
    hostname = socket.gethostname()
    now = datetime.now(tz=ZoneInfo(timezone))

    lines = ["\U0001f916 ãƒœãƒƒãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"ãƒ›ã‚¹ãƒˆ: {hostname}"]

    if env_name:
        lines.append(f"ç’°å¢ƒ: {env_name}")

    if bot_start_time is not None:
        start_str = bot_start_time.strftime("%Y-%m-%d %H:%M:%S %Z")
        uptime = now - bot_start_time
        uptime_str = _format_uptime(uptime.total_seconds())
        lines.append(f"èµ·å‹•: {start_str}ï¼ˆç¨¼åƒ {uptime_str}ï¼‰")

    return "\n".join(lines)


def _parse_rag_command(text: str) -> tuple[str, str, str, str]:
    """ragã‚³ãƒãƒ³ãƒ‰ã‚’è§£æã™ã‚‹."""
    tokens = text.split()
    if len(tokens) < 2:
        return ("", "", "", "")

    subcommand = tokens[1].lower()
    url = ""
    pattern = ""
    raw_url_token = ""

    if len(tokens) >= 3:
        url_token = tokens[2].strip("<>")
        if "|" in url_token:
            url_token = url_token.split("|")[0]
        raw_url_token = url_token
        if url_token.startswith("http://") or url_token.startswith("https://"):
            url = url_token

    if len(tokens) >= 4:
        pattern = " ".join(tokens[3:])

    return (subcommand, url, pattern, raw_url_token)


# --- Feed ãƒãƒ³ãƒ‰ãƒ©ç¾¤ ---


async def _handle_feed_add(
    collector: FeedCollector, urls: list[str], category: str
) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰è¿½åŠ å‡¦ç†."""
    if not urls:
        return "ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `@bot feed add https://example.com/rss [ã‚«ãƒ†ã‚´ãƒª]`"

    results: list[str] = []
    for url in urls:
        try:
            name = await collector.fetch_feed_title(url)
            feed = await collector.add_feed(url, name, category)
            results.append(f"âœ… {feed.url} ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ˆåå‰: {feed.name}ã€ã‚«ãƒ†ã‚´ãƒª: {feed.category}ï¼‰")
        except ValueError as e:
            results.append(f"âŒ {url}: {e}")
        except Exception:
            logger.exception("Failed to add feed: %s", url)
            results.append(f"âŒ {url}: è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

    return "\n".join(results)


async def _handle_feed_list(collector: FeedCollector) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§è¡¨ç¤ºå‡¦ç†."""
    enabled, disabled = await collector.list_feeds()

    if not enabled and not disabled:
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"

    lines: list[str] = []
    if enabled:
        lines.append("*æœ‰åŠ¹ãªãƒ•ã‚£ãƒ¼ãƒ‰*")
        for feed in enabled:
            lines.append(f"â€¢ {feed.url} â€” {feed.name}")
    else:
        lines.append("æœ‰åŠ¹ãªãƒ•ã‚£ãƒ¼ãƒ‰ã¯ã‚ã‚Šã¾ã›ã‚“")

    if disabled:
        lines.append("\n*ç„¡åŠ¹ãªãƒ•ã‚£ãƒ¼ãƒ‰*")
        for feed in disabled:
            lines.append(f"â€¢ {feed.url} â€” {feed.name}")

    return "\n".join(lines)


async def _handle_feed_delete(collector: FeedCollector, urls: list[str]) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰å‰Šé™¤å‡¦ç†."""
    if not urls:
        return "ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `@bot feed delete https://example.com/rss`"

    results: list[str] = []
    for url in urls:
        try:
            await collector.delete_feed(url)
            results.append(f"âœ… {url} ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        except ValueError as e:
            results.append(f"âŒ {url}: {e}")
        except Exception:
            logger.exception("Failed to delete feed: %s", url)
            results.append(f"âŒ {url}: å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

    return "\n".join(results)


async def _handle_feed_enable(collector: FeedCollector, urls: list[str]) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–å‡¦ç†."""
    if not urls:
        return "ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `@bot feed enable https://example.com/rss`"

    results: list[str] = []
    for url in urls:
        try:
            await collector.enable_feed(url)
            results.append(f"âœ… {url} ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
        except ValueError as e:
            results.append(f"âŒ {url}: {e}")
        except Exception:
            logger.exception("Failed to enable feed: %s", url)
            results.append(f"âŒ {url}: æœ‰åŠ¹åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

    return "\n".join(results)


async def _handle_feed_disable(collector: FeedCollector, urls: list[str]) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ç„¡åŠ¹åŒ–å‡¦ç†."""
    if not urls:
        return "ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `@bot feed disable https://example.com/rss`"

    results: list[str] = []
    for url in urls:
        try:
            await collector.disable_feed(url)
            results.append(f"âœ… {url} ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")
        except ValueError as e:
            results.append(f"âŒ {url}: {e}")
        except Exception:
            logger.exception("Failed to disable feed: %s", url)
            results.append(f"âŒ {url}: ç„¡åŠ¹åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

    return "\n".join(results)


async def _download_and_parse_csv(
    files: list[dict[str, object]] | None,
    bot_token: str,
) -> tuple[list[dict[str, str]], str | None]:
    """CSVæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ‘ãƒ¼ã‚¹ã™ã‚‹."""
    if not files:
        return ([], (
            "ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚\n"
            "ä½¿ç”¨æ–¹æ³•: `@bot feed import` ã¾ãŸã¯ `@bot feed replace` ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜\n"
            "CSVå½¢å¼: `url,name,category`"
        ))

    csv_file = None
    for f in files:
        mimetype = str(f.get("mimetype", ""))
        name = str(f.get("name", ""))
        if mimetype == "text/csv" or name.endswith(".csv"):
            csv_file = f
            break

    if not csv_file:
        return ([], (
            "ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            "CSVå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.csvï¼‰ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚"
        ))

    max_file_size = 1 * 1024 * 1024
    file_size = csv_file.get("size", 0)
    if isinstance(file_size, int) and file_size > max_file_size:
        return ([], f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆæœ€å¤§1MBã€å®Ÿéš›: {file_size // 1024}KBï¼‰")

    url_private = csv_file.get("url_private")
    if not url_private or not isinstance(url_private, str):
        return ([], "ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    download_url = csv_file.get("url_private_download") or url_private
    if not isinstance(download_url, str):
        download_url = url_private

    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(
                download_url,
                headers={"Authorization": f"Bearer {bot_token}"},
                follow_redirects=False,
            )
            if response.status_code == 302:
                logger.error("File download redirected - auth may have failed")
                return ([], "ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆèªè¨¼ã‚¨ãƒ©ãƒ¼ï¼‰ã€‚Botæ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            response.raise_for_status()
            content = response.text
    except httpx.HTTPError as e:
        logger.exception("Failed to download CSV file")
        return ([], f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    try:
        reader = csv.DictReader(io.StringIO(content))
        fieldnames = reader.fieldnames or []
        if "url" not in fieldnames or "name" not in fieldnames:
            return ([], (
                "ã‚¨ãƒ©ãƒ¼: CSVãƒ˜ãƒƒãƒ€ãƒ¼ãŒä¸æ­£ã§ã™ã€‚\n"
                "`url,name,category` ã®å½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚\n"
                f"æ¤œå‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼: {', '.join(fieldnames)}"
            ))

        rows = list(reader)
    except csv.Error as e:
        return ([], f"ã‚¨ãƒ©ãƒ¼: CSVã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    if not rows:
        return ([], "ã‚¨ãƒ©ãƒ¼: CSVã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    return (rows, None)


async def _import_feeds_from_rows(
    collector: FeedCollector,
    rows: list[dict[str, str]],
) -> tuple[int, list[str]]:
    """CSVã®è¡Œãƒªã‚¹ãƒˆã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç™»éŒ²ã™ã‚‹."""
    success_count = 0
    errors: list[str] = []

    for line_number, row in enumerate(rows, start=2):
        url = (row.get("url") or "").strip()
        name = (row.get("name") or "").strip()
        category = (row.get("category") or "").strip() or "ä¸€èˆ¬"

        if not url or not name:
            errors.append(f"è¡Œ{line_number}: url ã¾ãŸã¯ name ãŒç©ºã§ã™")
            continue

        parsed = urlparse(url)
        if parsed.scheme not in ("http", "https") or not parsed.netloc:
            errors.append(f"è¡Œ{line_number}: ç„¡åŠ¹ãªURLå½¢å¼ã§ã™ï¼ˆ{url}ï¼‰")
            continue

        try:
            await collector.add_feed(url, name, category)
            success_count += 1
        except ValueError as e:
            errors.append(f"è¡Œ{line_number}: {e}")
        except Exception:
            logger.exception("Failed to add feed: %s", url)
            errors.append(f"è¡Œ{line_number}: è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

    return (success_count, errors)


def _format_error_details(errors: list[str]) -> list[str]:
    """ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹."""
    lines: list[str] = []
    if errors:
        lines.append("\n*ã‚¨ãƒ©ãƒ¼è©³ç´°:*")
        for error in errors[:10]:
            lines.append(f"  â€¢ {error}")
        if len(errors) > 10:
            lines.append(f"  ...ä»– {len(errors) - 10}ä»¶")
    return lines


async def _handle_feed_import(
    collector: FeedCollector,
    files: list[dict[str, object]] | None,
    bot_token: str,
) -> str:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹."""
    rows, error = await _download_and_parse_csv(files, bot_token)
    if error is not None:
        return error

    success_count, errors = await _import_feeds_from_rows(collector, rows)

    result_lines = [
        "*ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†*",
        f"âœ… æˆåŠŸ: {success_count}ä»¶",
        f"âŒ å¤±æ•—: {len(errors)}ä»¶",
    ]
    result_lines.extend(_format_error_details(errors))

    return "\n".join(result_lines)


async def _handle_feed_replace(
    collector: FeedCollector,
    files: list[dict[str, object]] | None,
    bot_token: str,
) -> str:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã§å…¨ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç½®æ›ã™ã‚‹ï¼ˆå…¨å‰Šé™¤â†’å†ç™»éŒ²ï¼‰."""
    rows, error = await _download_and_parse_csv(files, bot_token)
    if error is not None:
        return error

    try:
        deleted_count = await collector.delete_all_feeds()
    except Exception:
        logger.exception("Failed to delete all feeds in replace")
        return (
            "*ãƒ•ã‚£ãƒ¼ãƒ‰ç½®æ›ã‚¨ãƒ©ãƒ¼*\n"
            "ğŸ—‘ï¸ æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ‰ã®å‰Šé™¤ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
            "âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ã®ç½®æ›ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        )

    try:
        success_count, errors = await _import_feeds_from_rows(collector, rows)
    except Exception:
        logger.exception("Failed to import feeds after delete_all in replace")
        return (
            "*ãƒ•ã‚£ãƒ¼ãƒ‰ç½®æ›ã‚¨ãƒ©ãƒ¼*\n"
            f"ğŸ—‘ï¸ å‰Šé™¤: {deleted_count}ä»¶ï¼ˆæ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ‰ï¼‰\n"
            "âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        )

    result_lines = [
        "*ãƒ•ã‚£ãƒ¼ãƒ‰ç½®æ›å®Œäº†*",
        f"ğŸ—‘ï¸ å‰Šé™¤: {deleted_count}ä»¶ï¼ˆæ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ‰ï¼‰",
        f"âœ… ç™»éŒ²æˆåŠŸ: {success_count}ä»¶",
        f"âŒ ç™»éŒ²å¤±æ•—: {len(errors)}ä»¶",
    ]
    result_lines.extend(_format_error_details(errors))

    return "\n".join(result_lines)


async def _handle_feed_export_via_port(
    collector: FeedCollector,
    messaging: MessagingPort,
    thread_id: str,
    channel: str,
) -> str:
    """å…¨ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ï¼ˆMessagingPortçµŒç”±ï¼‰."""
    feeds = await collector.get_all_feeds()

    if not feeds:
        return "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    def _sanitize_csv_field(value: str) -> str:
        if value and value[0] in ("=", "+", "-", "@"):
            return f"'{value}"
        return value

    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(["url", "name", "category"])
    for feed in feeds:
        writer.writerow([
            feed.url,
            _sanitize_csv_field(feed.name),
            _sanitize_csv_field(feed.category),
        ])
    csv_content = output.getvalue()

    try:
        await messaging.upload_file(
            content=csv_content,
            filename="feeds.csv",
            thread_id=thread_id,
            channel=channel,
            comment=f"ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸï¼ˆ{len(feeds)}ä»¶ï¼‰",
        )
    except Exception as e:
        error_msg = str(e)
        if "missing_scope" in error_msg or "not_allowed_token_type" in error_msg:
            logger.error("File upload failed due to missing scope: %s", e)
            return (
                "ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
                "Slack Appã« `files:write` ã‚¹ã‚³ãƒ¼ãƒ—ã®è¿½åŠ ãŒå¿…è¦ã§ã™ã€‚"
            )
        logger.exception("Failed to upload CSV file")
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

    return ""


async def _safe_extract_profile(
    profiler: UserProfiler, user_id: str, message: str
) -> None:
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡ºã‚’å®‰å…¨ã«å®Ÿè¡Œã™ã‚‹ï¼ˆä¾‹å¤–ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼‰."""
    try:
        await profiler.extract_profile(user_id, message)
    except Exception:
        logger.exception("Failed to extract user profile for %s", user_id)


class MessageRouter:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° + ã‚µãƒ¼ãƒ“ã‚¹å±¤å‘¼ã³å‡ºã—.

    ä»•æ§˜: docs/specs/features/cli-adapter.md
    """

    def __init__(
        self,
        messaging: MessagingPort,
        chat_service: ChatService,
        user_profiler: UserProfiler | None = None,
        topic_recommender: TopicRecommender | None = None,
        collector: FeedCollector | None = None,
        session_factory: async_sessionmaker[AsyncSession] | None = None,
        channel_id: str | None = None,
        max_articles_per_feed: int = 10,
        feed_card_layout: Literal["vertical", "horizontal"] = "horizontal",
        bot_token: str | None = None,
        timezone: str = "Asia/Tokyo",
        env_name: str = "",
        mcp_manager: MCPClientManager | None = None,
        bot_start_time: datetime | None = None,
        slack_client: AsyncWebClient | None = None,
    ) -> None:
        self._messaging = messaging
        self._chat_service = chat_service
        self._user_profiler = user_profiler
        self._topic_recommender = topic_recommender
        self._collector = collector
        self._session_factory = session_factory
        self._channel_id = channel_id
        self._max_articles_per_feed = max_articles_per_feed
        self._feed_card_layout = feed_card_layout
        self._bot_token = bot_token
        self._timezone = timezone
        self._env_name = env_name
        self._mcp_manager = mcp_manager
        self._bot_start_time = bot_start_time
        self._slack_client = slack_client

    async def process_message(self, msg: IncomingMessage) -> None:
        """å—ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—ã€é©åˆ‡ãªã‚µãƒ¼ãƒ“ã‚¹ã«å§”è­²ã™ã‚‹."""
        cleaned_text = msg.text
        user_id = msg.user_id
        thread_id = msg.thread_id
        channel = msg.channel

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒãƒ³ãƒ‰ (F7)
        if cleaned_text.lower().strip() in _STATUS_KEYWORDS:
            response_text = _build_status_message(
                self._timezone, self._env_name, self._bot_start_time
            )
            await self._messaging.send_message(response_text, thread_id, channel)
            return

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (F3-AC4, F6-AC4)
        if self._user_profiler is not None and any(
            kw in cleaned_text.lower() for kw in _PROFILE_KEYWORDS
        ):
            profile_text = await self._user_profiler.get_profile(user_id)
            if profile_text:
                await self._messaging.send_message(profile_text, thread_id, channel)
            else:
                await self._messaging.send_message(
                    "ã¾ã ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¼šè©±ã‚’ç¶šã‘ã‚‹ã¨è‡ªå‹•çš„ã«è¨˜éŒ²ã•ã‚Œã¾ã™ï¼",
                    thread_id, channel,
                )
            return

        # feedã‚³ãƒãƒ³ãƒ‰ (F2-AC7, F6-AC4)
        lower_text = cleaned_text.lower().lstrip()
        if self._collector is not None and any(
            re.match(rf"^{re.escape(kw)}\b", lower_text) for kw in _FEED_KEYWORDS
        ):
            await self._handle_feed_command(msg, cleaned_text, lower_text)
            return

        # ragã‚³ãƒãƒ³ãƒ‰ (F9)
        if self._mcp_manager is not None and any(
            re.match(rf"^{re.escape(kw)}\b", lower_text) for kw in _RAG_KEYWORDS
        ):
            await self._handle_rag_command(msg, cleaned_text)
            return

        # é…ä¿¡ãƒ†ã‚¹ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (F2)
        if (
            self._collector is not None
            and self._session_factory is not None
            and self._channel_id is not None
            and any(kw in cleaned_text.lower() for kw in _DELIVER_KEYWORDS)
        ):
            await self._handle_deliver(msg)
            return

        # ãƒˆãƒ”ãƒƒã‚¯ææ¡ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (F4, F6-AC4)
        if self._topic_recommender is not None and any(
            kw in cleaned_text.lower() for kw in _TOPIC_KEYWORDS
        ):
            try:
                recommendation = await self._topic_recommender.recommend(user_id)
                await self._messaging.send_message(recommendation, thread_id, channel)
            except Exception:
                logger.exception("Failed to generate topic recommendation")
                await self._messaging.send_message(
                    "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒˆãƒ”ãƒƒã‚¯ææ¡ˆã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    thread_id, channel,
                )
            return

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ChatService ã§å¿œç­”
        try:
            response = await self._chat_service.respond(
                user_id=user_id,
                text=cleaned_text,
                thread_ts=thread_id,
                channel=channel,
                is_in_thread=msg.is_in_thread,
                current_ts=msg.message_id,
            )
            await self._messaging.send_message(response, thread_id, channel)

            if self._user_profiler is not None:
                asyncio.create_task(
                    _safe_extract_profile(self._user_profiler, user_id, cleaned_text)
                )
        except Exception:
            logger.exception("Failed to generate response")
            await self._messaging.send_message(
                "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                thread_id, channel,
            )

    async def _handle_feed_command(
        self, msg: IncomingMessage, cleaned_text: str, lower_text: str
    ) -> None:
        """feedã‚³ãƒãƒ³ãƒ‰ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°."""
        assert self._collector is not None
        thread_id = msg.thread_id
        channel = msg.channel

        subcommand, urls, category = _parse_feed_command(cleaned_text)

        if subcommand == "add":
            response_text = await _handle_feed_add(self._collector, urls, category)
        elif subcommand == "list":
            response_text = await _handle_feed_list(self._collector)
        elif subcommand == "delete":
            response_text = await _handle_feed_delete(self._collector, urls)
        elif subcommand == "enable":
            response_text = await _handle_feed_enable(self._collector, urls)
        elif subcommand == "disable":
            response_text = await _handle_feed_disable(self._collector, urls)
        elif subcommand == "import":
            if not self._bot_token:
                response_text = "ã‚¨ãƒ©ãƒ¼: Bot TokenãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            else:
                response_text = await _handle_feed_import(
                    self._collector, msg.files, self._bot_token
                )
        elif subcommand == "replace":
            if not self._bot_token:
                response_text = "ã‚¨ãƒ©ãƒ¼: Bot TokenãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            else:
                response_text = await _handle_feed_replace(
                    self._collector, msg.files, self._bot_token
                )
        elif subcommand == "export":
            response_text = await _handle_feed_export_via_port(
                self._collector, self._messaging, thread_id, channel
            )
            if response_text:
                await self._messaging.send_message(response_text, thread_id, channel)
            return
        elif subcommand == "collect":
            await self._handle_feed_collect(msg, cleaned_text)
            return
        elif subcommand == "test":
            await self._handle_feed_test(msg)
            return
        else:
            response_text = (
                "ä½¿ç”¨æ–¹æ³•:\n"
                "â€¢ `@bot feed add <URL> [ã‚«ãƒ†ã‚´ãƒª]` â€” ãƒ•ã‚£ãƒ¼ãƒ‰è¿½åŠ \n"
                "â€¢ `@bot feed list` â€” ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§\n"
                "â€¢ `@bot feed delete <URL>` â€” ãƒ•ã‚£ãƒ¼ãƒ‰å‰Šé™¤\n"
                "â€¢ `@bot feed enable <URL>` â€” ãƒ•ã‚£ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–\n"
                "â€¢ `@bot feed disable <URL>` â€” ãƒ•ã‚£ãƒ¼ãƒ‰ç„¡åŠ¹åŒ–\n"
                "â€¢ `@bot feed import` + CSVæ·»ä»˜ â€” ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n"
                "â€¢ `@bot feed replace` + CSVæ·»ä»˜ â€” ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€æ‹¬ç½®æ›\n"
                "â€¢ `@bot feed export` â€” ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§ã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n"
                "â€¢ `@bot feed collect --skip-summary` â€” è¦ç´„ãªã—ä¸€æ‹¬åé›†\n"
                "â€¢ `@bot feed test` â€” ãƒ†ã‚¹ãƒˆé…ä¿¡ï¼ˆä¸Šä½3ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ»å„5ä»¶ï¼‰\n"
                "â€» URLãƒ»ã‚«ãƒ†ã‚´ãƒªã¯è¤‡æ•°æŒ‡å®šå¯èƒ½ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰"
            )

        await self._messaging.send_message(response_text, thread_id, channel)

    async def _handle_feed_collect(
        self, msg: IncomingMessage, cleaned_text: str
    ) -> None:
        """feed collect ã‚³ãƒãƒ³ãƒ‰å‡¦ç†."""
        thread_id = msg.thread_id
        channel = msg.channel

        if "--skip-summary" in cleaned_text.lower():
            if (
                self._collector is not None
                and self._session_factory is not None
                and self._channel_id is not None
                and self._slack_client is not None
            ):
                from src.scheduler.jobs import daily_collect_and_deliver

                try:
                    await self._messaging.send_message(
                        "è¦ç´„ã‚¹ã‚­ãƒƒãƒ—åé›†ã‚’é–‹å§‹ã—ã¾ã™...", thread_id, channel
                    )
                    feed_count, article_count = await daily_collect_and_deliver(
                        self._collector, self._session_factory,
                        self._slack_client, self._channel_id,
                        max_articles_per_feed=self._max_articles_per_feed,
                        layout=self._feed_card_layout,
                        skip_summary=True,
                    )
                    await self._messaging.send_message(
                        f"è¦ç´„ã‚¹ã‚­ãƒƒãƒ—åé›†ãŒå®Œäº†ã—ã¾ã—ãŸ\nåé›†ãƒ•ã‚£ãƒ¼ãƒ‰æ•°: {feed_count}\nåé›†è¨˜äº‹æ•°: {article_count}",
                        thread_id, channel,
                    )
                except Exception:
                    logger.exception("Failed to collect feeds with skip-summary")
                    await self._messaging.send_message(
                        "è¦ç´„ã‚¹ã‚­ãƒƒãƒ—åé›†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                        thread_id, channel,
                    )
            else:
                await self._messaging.send_message(
                    "ã‚¨ãƒ©ãƒ¼: é…ä¿¡è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚", thread_id, channel
                )
        else:
            response_text = (
                "ä½¿ç”¨æ–¹æ³•:\n"
                "â€¢ `@bot feed collect --skip-summary` â€” è¦ç´„ãªã—ä¸€æ‹¬åé›†"
            )
            await self._messaging.send_message(response_text, thread_id, channel)

    async def _handle_feed_test(self, msg: IncomingMessage) -> None:
        """feed test ã‚³ãƒãƒ³ãƒ‰å‡¦ç†."""
        thread_id = msg.thread_id
        channel = msg.channel

        if (
            self._session_factory is not None
            and self._channel_id is not None
            and self._slack_client is not None
        ):
            from src.scheduler.jobs import feed_test_deliver

            try:
                await self._messaging.send_message(
                    "ãƒ†ã‚¹ãƒˆé…ä¿¡ã‚’é–‹å§‹ã—ã¾ã™...", thread_id, channel
                )
                await feed_test_deliver(
                    session_factory=self._session_factory,
                    slack_client=self._slack_client,
                    channel_id=self._channel_id,
                    layout=self._feed_card_layout,
                )
                await self._messaging.send_message(
                    "ãƒ†ã‚¹ãƒˆé…ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸ", thread_id, channel
                )
            except Exception:
                logger.exception("Failed to run feed test delivery")
                await self._messaging.send_message(
                    "ãƒ†ã‚¹ãƒˆé…ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    thread_id, channel,
                )
        else:
            await self._messaging.send_message(
                "ã‚¨ãƒ©ãƒ¼: é…ä¿¡è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆSlackæ¥ç¶šãŒå¿…è¦ã§ã™ï¼‰ã€‚",
                thread_id, channel,
            )

    async def _handle_deliver(self, msg: IncomingMessage) -> None:
        """deliver ã‚³ãƒãƒ³ãƒ‰å‡¦ç†."""
        assert self._collector is not None
        assert self._session_factory is not None
        assert self._channel_id is not None
        thread_id = msg.thread_id
        channel = msg.channel

        if self._slack_client is None:
            await self._messaging.send_message(
                "ã‚¨ãƒ©ãƒ¼: deliver ã‚³ãƒãƒ³ãƒ‰ã¯ Slack æ¥ç¶šæ™‚ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚",
                thread_id, channel,
            )
            return

        from src.scheduler.jobs import daily_collect_and_deliver

        try:
            await self._messaging.send_message(
                "é…ä¿¡ã‚’é–‹å§‹ã—ã¾ã™...", thread_id, channel
            )
            await daily_collect_and_deliver(
                self._collector, self._session_factory,
                self._slack_client, self._channel_id,
                max_articles_per_feed=self._max_articles_per_feed,
                layout=self._feed_card_layout,
            )
            await self._messaging.send_message(
                "é…ä¿¡ãŒå®Œäº†ã—ã¾ã—ãŸ", thread_id, channel
            )
        except Exception:
            logger.exception("Failed to run manual delivery")
            await self._messaging.send_message(
                "é…ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", thread_id, channel
            )

    async def _handle_rag_command(
        self, msg: IncomingMessage, cleaned_text: str
    ) -> None:
        """ragã‚³ãƒãƒ³ãƒ‰ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆMCPçµŒç”±ï¼‰."""
        assert self._mcp_manager is not None
        thread_id = msg.thread_id
        channel = msg.channel

        subcommand, url, pattern, raw_url_token = _parse_rag_command(cleaned_text)

        if subcommand == "crawl":
            await self._handle_rag_crawl_mcp(
                url, pattern, raw_url_token, thread_id, channel,
            )
            return
        elif subcommand == "add":
            response_text = await self._call_rag_url_tool(
                "rag_add", url, raw_url_token,
                usage_hint="ä¾‹: `@bot rag add https://example.com/page`",
            )
        elif subcommand == "status":
            try:
                response_text = await self._mcp_manager.call_tool("rag_stats", {})
            except MCPToolNotFoundError:
                response_text = "ã‚¨ãƒ©ãƒ¼: RAGçµ±è¨ˆãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
            except Exception:
                logger.exception("Failed to call rag_stats tool")
                response_text = "ã‚¨ãƒ©ãƒ¼: çµ±è¨ˆæƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        elif subcommand == "delete":
            response_text = await self._call_rag_url_tool(
                "rag_delete", url, raw_url_token,
                usage_hint="ä¾‹: `@bot rag delete https://example.com/page`",
            )
        else:
            response_text = (
                "ä½¿ç”¨æ–¹æ³•:\n"
                "â€¢ `@bot rag crawl <URL> [ãƒ‘ã‚¿ãƒ¼ãƒ³]` â€” ãƒªãƒ³ã‚¯é›†ãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚¯ãƒ­ãƒ¼ãƒ«ï¼†å–ã‚Šè¾¼ã¿\n"
                "â€¢ `@bot rag add <URL>` â€” å˜ä¸€ãƒšãƒ¼ã‚¸å–ã‚Šè¾¼ã¿\n"
                "â€¢ `@bot rag status` â€” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º\n"
                "â€¢ `@bot rag delete <URL>` â€” ã‚½ãƒ¼ã‚¹URLæŒ‡å®šã§å‰Šé™¤"
            )

        if response_text:
            await self._messaging.send_message(response_text, thread_id, channel)

    async def _handle_rag_crawl_mcp(
        self,
        url: str,
        pattern: str,
        raw_url_token: str,
        thread_id: str,
        channel: str,
    ) -> None:
        """RAGã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†ï¼ˆMCPçµŒç”±ï¼‰."""
        assert self._mcp_manager is not None
        if not url:
            if raw_url_token:
                error = f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªURLã‚¹ã‚­ãƒ¼ãƒ ã§ã™: {raw_url_token}\nhttp:// ã¾ãŸã¯ https:// ã§å§‹ã¾ã‚‹URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            else:
                error = "ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `@bot rag crawl https://example.com/docs [ãƒ‘ã‚¿ãƒ¼ãƒ³]`"
            await self._messaging.send_message(error, thread_id, channel)
            return

        # é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
        try:
            await self._messaging.send_message(
                "ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’é–‹å§‹ã—ã¾ã—ãŸ... (ãƒªãƒ³ã‚¯åé›†ä¸­)",
                thread_id, channel,
            )
        except Exception:
            logger.debug("Failed to post start message", exc_info=True)

        # MCP ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—
        try:
            result = await self._mcp_manager.call_tool(
                "rag_crawl", {"url": url, "pattern": pattern},
            )
            response_text = result if result.startswith("ã‚¨ãƒ©ãƒ¼:") else f"â””â”€ {result}"
        except MCPToolNotFoundError:
            response_text = "ã‚¨ãƒ©ãƒ¼: RAGã‚¯ãƒ­ãƒ¼ãƒ«ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
        except Exception:
            logger.exception("Failed to call rag_crawl tool")
            response_text = "ã‚¨ãƒ©ãƒ¼: ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

        await self._messaging.send_message(response_text, thread_id, channel)

    async def _call_rag_url_tool(
        self,
        tool_name: str,
        url: str,
        raw_url_token: str,
        usage_hint: str,
    ) -> str:
        """URLå¿…é ˆã®RAGãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼."""
        assert self._mcp_manager is not None
        if not url:
            if raw_url_token:
                return f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªURLã‚¹ã‚­ãƒ¼ãƒ ã§ã™: {raw_url_token}\nhttp:// ã¾ãŸã¯ https:// ã§å§‹ã¾ã‚‹URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            return f"ã‚¨ãƒ©ãƒ¼: URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\n{usage_hint}"

        try:
            return await self._mcp_manager.call_tool(tool_name, {"url": url})
        except MCPToolNotFoundError:
            return f"ã‚¨ãƒ©ãƒ¼: ãƒ„ãƒ¼ãƒ« '{tool_name}' ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
        except Exception:
            logger.exception("Failed to call %s tool", tool_name)
            return f"ã‚¨ãƒ©ãƒ¼: ãƒ„ãƒ¼ãƒ« '{tool_name}' ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
